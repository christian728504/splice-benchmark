{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/pi/zhiping.weng-umw/data/ramirezc/tissue_specific')\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyfaidx import Fasta\n",
    "from typing import Dict, Tuple, Set, Optional\n",
    "from conssensus_evaluator import ConsensusSpliceSiteEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = ConsensusSpliceSiteEvaluator(\n",
    "    gencode_gtf=\"path/to/gencode.v47.gtf\",\n",
    "    consensus_fasta=\"path/to/consensus.fa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for expressed genes\n",
    "expressed_genes = evaluator.filter_expressed_genes(\n",
    "    quant_tsv=\"path/to/quantifications.tsv\",\n",
    "    min_tpm=2.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ground truth with serialization\n",
    "ground_truth_acceptor, ground_truth_donor = evaluator.parse_gencode(\n",
    "    expressed_genes=expressed_genes,\n",
    "    ground_truth_file=\"ground_truth.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with serialization\n",
    "pred_acceptor, pred_donor = evaluator.generate_spliceai_predictions(\n",
    "    predictions_file=\"predictions.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "acceptor_precision, acceptor_recall, acceptor_auprc, acceptor_top_k = evaluator.calculate_metrics(\n",
    "    ground_truth_acceptor, \n",
    "    pred_acceptor\n",
    ")\n",
    "donor_precision, donor_recall, donor_auprc, donor_top_k = evaluator.calculate_metrics(\n",
    "    ground_truth_donor,\n",
    "    pred_donor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean metrics\n",
    "mean_auprc = (acceptor_auprc + donor_auprc) / 2\n",
    "mean_topk = (acceptor_top_k + donor_top_k) / 2\n",
    "\n",
    "# Plot precision-recall curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(acceptor_recall, acceptor_precision, label=f'Acceptor (AUPRC={acceptor_auprc:.3f})')\n",
    "plt.plot(donor_recall, donor_precision, label=f'Donor (AUPRC={donor_auprc:.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall Curves\\nMean AUPRC: {mean_auprc:.3f}, Mean Top-k: {mean_topk:.3f}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"auprc_topk_spliceai.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(f\"Acceptor AUPRC: {acceptor_auprc:.4f}, Top-k: {acceptor_top_k:.4f}\")\n",
    "print(f\"Donor AUPRC: {donor_auprc:.4f}, Top-k: {donor_topk:.4f}\")\n",
    "print(f\"Mean AUPRC: {mean_auprc:.4f}, Mean Top-k: {mean_topk:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
