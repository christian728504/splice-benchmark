{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e198d0-efa6-4097-be60-ef5586d40a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:26:04.490258Z",
     "iopub.status.busy": "2024-12-26T16:26:04.489834Z",
     "iopub.status.idle": "2024-12-26T16:26:07.670745Z",
     "shell.execute_reply": "2024-12-26T16:26:07.669426Z",
     "shell.execute_reply.started": "2024-12-26T16:26:04.490233Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from pyfaidx import Fasta\n",
    "import matplotlib.pyplot as plt\n",
    "from total_rnaseq_evaluator import SpliceSiteEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08bd5687-5229-4304-9730-f708d84fed9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:26:07.757719Z",
     "iopub.status.busy": "2024-12-26T16:26:07.756917Z",
     "iopub.status.idle": "2024-12-26T16:26:09.452287Z",
     "shell.execute_reply": "2024-12-26T16:26:09.451589Z",
     "shell.execute_reply.started": "2024-12-26T16:26:07.757693Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Faidx.__del__ at 0x14a0cfebd630>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/venv/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 883, in __del__\n",
      "    self.__exit__()\n",
      "  File \"/opt/venv/lib/python3.10/site-packages/pyfaidx/__init__.py\", line 889, in __exit__\n",
      "    self.file.close()\n",
      "AttributeError: 'Faidx' object has no attribute 'file'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: gencode grch37 gtf file not found, You can download from https://www.gencodegenes.org/human/release_19.html\n",
      "Please ignore this warning if you are using hg38\n",
      "hg19 fasta not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian.ramirez1-umw/data/Splice/SpliceTransformer/tasks_annotate_mutations.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  save_dict = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch device:cuda\n"
     ]
    }
   ],
   "source": [
    "# Paths to your files\n",
    "BAM_FILE = \"/data/Splice/data/ENCFF800HIP.bam\"\n",
    "FASTA_FILE = \"/data/genomes/hg38/hg38.fa\"\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = SpliceSiteEvaluator(\n",
    "    bam_file=BAM_FILE, \n",
    "    fasta_file=FASTA_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0c37a1-4924-4d03-83b1-156294adb746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:26:09.920013Z",
     "iopub.status.busy": "2024-12-26T16:26:09.919664Z",
     "iopub.status.idle": "2024-12-26T16:26:12.296430Z",
     "shell.execute_reply": "2024-12-26T16:26:12.295067Z",
     "shell.execute_reply.started": "2024-12-26T16:26:09.919993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing junctions.bed, using existing file...\n",
      "Median junction read count: 8.0\n",
      "\n",
      "Per-chromosome junction counts:\n",
      "chr1: Total junctions 10531, Positive acceptor sites: 5249, Positive donor sites: 5176\n",
      "chr3: Total junctions 6034, Positive acceptor sites: 2882, Positive donor sites: 2861\n",
      "chr5: Total junctions 4378, Positive acceptor sites: 2095, Positive donor sites: 2077\n",
      "chr7: Total junctions 4981, Positive acceptor sites: 2218, Positive donor sites: 2194\n",
      "chr9: Total junctions 4182, Positive acceptor sites: 2052, Positive donor sites: 2027\n"
     ]
    }
   ],
   "source": [
    "# Generate ground truth\n",
    "acceptor_ground_truth, donor_ground_truth = evaluator.generate_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e1700-5e11-4617-841e-ed33ecbd4085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "acceptor_predictions, donor_predictions = evaluator.generate_predictions(\n",
    "    ground_truth=acceptor_ground_truth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11fe3273-6d3e-4e6f-a720-cd8b1e7eae48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:26:13.780959Z",
     "iopub.status.busy": "2024-12-26T16:26:13.780516Z",
     "iopub.status.idle": "2024-12-26T16:26:13.786091Z",
     "shell.execute_reply": "2024-12-26T16:26:13.785456Z",
     "shell.execute_reply.started": "2024-12-26T16:26:13.780936Z"
    }
   },
   "outputs": [],
   "source": [
    "def save(data, name):\n",
    "    \"\"\"Save object to a pickle file in current directory.\"\"\"\n",
    "    with open(f\"{name}.pkl\", 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load(name):\n",
    "    \"\"\"Load object from a pickle file in current directory.\"\"\"\n",
    "    with open(f\"{name}.pkl\", 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf445829-6e86-4221-8bba-4d7441fc4b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:26:13.985374Z",
     "iopub.status.busy": "2024-12-26T16:26:13.984835Z",
     "iopub.status.idle": "2024-12-26T16:26:26.647996Z",
     "shell.execute_reply": "2024-12-26T16:26:26.646874Z",
     "shell.execute_reply.started": "2024-12-26T16:26:13.985354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save objects\n",
    "save(acceptor_ground_truth, \"acceptor_ground_truth\")\n",
    "save(donor_ground_truth, \"donor_ground_truth\")\n",
    "# save(acceptor_predictions, \"acceptor_predictions\")\n",
    "# save(donor_predictions, \"donor_predictions\")\n",
    "\n",
    "# Load objects\n",
    "acceptor_ground_truth = load(\"acceptor_ground_truth\")\n",
    "donor_ground_truth = load(\"donor_ground_truth\")\n",
    "acceptor_predictions = load(\"acceptor_predictions\")\n",
    "donor_predictions = load(\"donor_predictions_corrected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57172e9-46c0-43d8-87be-111b4499f342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:26:26.649579Z",
     "iopub.status.busy": "2024-12-26T16:26:26.649184Z",
     "iopub.status.idle": "2024-12-26T16:26:27.515872Z",
     "shell.execute_reply": "2024-12-26T16:26:27.515328Z",
     "shell.execute_reply.started": "2024-12-26T16:26:26.649558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27573  62915 198095 829002 925921 930154 931038 935771 939039 939274\n",
      " 942409 942558 943252 943697 943907 948510 961292 961628 961825 962285]\n",
      "10999\n",
      "[ 15038  15877  16952  17328  17704  18009  18364  24808  24819 139847\n",
      " 155788 164334 165942 168178 169139 172645 173850 185580 186415 187214]\n",
      "5249\n",
      "[ 30667 201181 366259 779092 827775 829104 882367 924948 926013 930336\n",
      " 931089 935896 939129 939412 942251 942488 943058 943377 943808 960800]\n",
      "10685\n",
      "[ 14744  14969  16673  16957  17286  17643  17962  18272  18294 139632\n",
      " 146417 158622 164695 165883 168099 169174 172599 185251 185490 186370]\n",
      "5176\n",
      "1\n",
      "0\n",
      "{'chr1': array([0.00000000e+00, 1.82558438e-07, 1.78821651e-07, ...,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00]), 'chr3': array([0.00000000e+00, 1.82558438e-07, 1.78821651e-07, ...,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00]), 'chr5': array([0.00000000e+00, 1.82558438e-07, 1.78821651e-07, ...,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00]), 'chr7': array([0.00000000e+00, 1.82558438e-07, 1.78821651e-07, ...,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00]), 'chr9': array([0.00000000e+00, 1.82558438e-07, 1.78821651e-07, ...,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00])}\n"
     ]
    }
   ],
   "source": [
    "# chromosomes = ['chr1', 'chr3', 'chr5', 'chr7', 'chr9']\n",
    "chromosomes = ['chr1']\n",
    "\n",
    "acceptor_prediction_indices = np.concatenate([\n",
    "    np.where(acceptor_predictions[chrom] >= 0.90)[0] \n",
    "    for chrom in chromosomes\n",
    "])\n",
    "print(acceptor_prediction_indices[:20])\n",
    "print(len(acceptor_prediction_indices))\n",
    "acceptor_truth_indices = np.concatenate([\n",
    "    np.where(acceptor_ground_truth[chrom] == 1)[0] \n",
    "    for chrom in chromosomes\n",
    "])\n",
    "print(acceptor_truth_indices[:20])\n",
    "print(len(acceptor_truth_indices))\n",
    "\n",
    "donor_prediction_indices = np.concatenate([\n",
    "    np.where(donor_predictions[chrom] >= 0.90)[0] \n",
    "    for chrom in chromosomes\n",
    "])\n",
    "print(donor_prediction_indices[:20])\n",
    "print(len(donor_prediction_indices))\n",
    "donor_truth_indices = np.concatenate([\n",
    "    np.where(donor_ground_truth[chrom] == 1)[0] \n",
    "    for chrom in chromosomes\n",
    "])\n",
    "print(donor_truth_indices[:20])\n",
    "print(len(donor_truth_indices))\n",
    "\n",
    "print(len(set(acceptor_prediction_indices) & set(acceptor_truth_indices)))\n",
    "print(len(set(donor_prediction_indices) & set(donor_truth_indices)))\n",
    "\n",
    "print(donor_predictions)\n",
    "\n",
    "# print(acceptor_ground_truth['chr1'][12612+4000-5:12612+4000+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b40f11-3b0b-4e08-899d-29c73cd05aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUPRC\n",
    "acceptor_auprc = evaluator.calculate_auprc(acceptor_ground_truth, acceptor_predictions)\n",
    "donor_auprc = evaluator.calculate_auprc(donor_ground_truth, donor_predictions)\n",
    "mean_auprc = (acceptor_auprc + donor_auprc) / 2\n",
    "print(acceptor_auprc)\n",
    "print(donor_auprc)\n",
    "print(f\"{mean_auprc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42f829-877d-4c57-8a44-66e95fbe24fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def diagnose_splice_site_alignment(acceptor_ground_truth, donor_ground_truth, \n",
    "#                                     acceptor_predictions, donor_predictions, \n",
    "#                                     threshold=0.9):\n",
    "#     \"\"\"\n",
    "#     Diagnostic method to analyze alignment between ground truth and predictions\n",
    "    \n",
    "#     Args:\n",
    "#         acceptor_ground_truth (dict): Ground truth for acceptor sites\n",
    "#         donor_ground_truth (dict): Ground truth for donor sites\n",
    "#         acceptor_predictions (dict): Predictions for acceptor sites\n",
    "#         donor_predictions (dict): Predictions for donor sites\n",
    "#         threshold (float): Probability threshold for considering a prediction positive\n",
    "#     \"\"\"\n",
    "#     print(\"Splice Site Alignment Diagnostics:\")\n",
    "    \n",
    "#     # Collect ground truth positions for each chromosome\n",
    "#     ground_truth_stats = {}\n",
    "    \n",
    "#     for chrom in acceptor_ground_truth.keys():\n",
    "#         # Find ground truth positions\n",
    "#         acceptor_gt_pos = np.where(acceptor_ground_truth[chrom] == 1)[0]\n",
    "#         donor_gt_pos = np.where(donor_ground_truth[chrom] == 1)[0]\n",
    "        \n",
    "#         # Find predicted positions\n",
    "#         acceptor_pred_pos = np.where(acceptor_predictions[chrom] >= threshold)[0]\n",
    "#         donor_pred_pos = np.where(donor_predictions[chrom] >= threshold)[0]\n",
    "        \n",
    "#         # Calculate matches\n",
    "#         acceptor_matches = np.intersect1d(acceptor_gt_pos, acceptor_pred_pos)\n",
    "#         donor_matches = np.intersect1d(donor_gt_pos, donor_pred_pos)\n",
    "        \n",
    "#         # Store statistics\n",
    "#         ground_truth_stats[chrom] = {\n",
    "#             'total_acceptor_gt': len(acceptor_gt_pos),\n",
    "#             'total_donor_gt': len(donor_gt_pos),\n",
    "#             'total_acceptor_pred': len(acceptor_pred_pos),\n",
    "#             'total_donor_pred': len(donor_pred_pos),\n",
    "#             'acceptor_matches': len(acceptor_matches),\n",
    "#             'donor_matches': len(donor_matches),\n",
    "#             'acceptor_match_percentage': len(acceptor_matches) / len(acceptor_gt_pos) * 100 if acceptor_gt_pos.size > 0 else 0,\n",
    "#             'donor_match_percentage': len(donor_matches) / len(donor_gt_pos) * 100 if donor_gt_pos.size > 0 else 0\n",
    "#         }\n",
    "    \n",
    "#     # Print detailed statistics\n",
    "#     print(\"\\nDetailed Chromosome Statistics:\")\n",
    "#     for chrom, stats in ground_truth_stats.items():\n",
    "#         print(f\"\\n{chrom} Statistics:\")\n",
    "#         print(f\"Acceptor Sites - Ground Truth: {stats['total_acceptor_gt']}, \"\n",
    "#               f\"Predictions: {stats['total_acceptor_pred']}, \"\n",
    "#               f\"Matches: {stats['acceptor_matches']} \"\n",
    "#               f\"(Match %: {stats['acceptor_match_percentage']:.2f}%)\")\n",
    "#         print(f\"Donor Sites - Ground Truth: {stats['total_donor_gt']}, \"\n",
    "#               f\"Predictions: {stats['total_donor_pred']}, \"\n",
    "#               f\"Matches: {stats['donor_matches']} \"\n",
    "#               f\"(Match %: {stats['donor_match_percentage']:.2f}%)\")\n",
    "    \n",
    "#     # Compute overall statistics\n",
    "#     total_stats = {\n",
    "#         'total_acceptor_gt': sum(stats['total_acceptor_gt'] for stats in ground_truth_stats.values()),\n",
    "#         'total_donor_gt': sum(stats['total_donor_gt'] for stats in ground_truth_stats.values()),\n",
    "#         'total_acceptor_pred': sum(stats['total_acceptor_pred'] for stats in ground_truth_stats.values()),\n",
    "#         'total_donor_pred': sum(stats['total_donor_pred'] for stats in ground_truth_stats.values()),\n",
    "#         'total_acceptor_matches': sum(stats['acceptor_matches'] for stats in ground_truth_stats.values()),\n",
    "#         'total_donor_matches': sum(stats['donor_matches'] for stats in ground_truth_stats.values())\n",
    "#     }\n",
    "    \n",
    "#     print(\"\\nOverall Statistics:\")\n",
    "#     print(f\"Total Acceptor Ground Truth Sites: {total_stats['total_acceptor_gt']}\")\n",
    "#     print(f\"Total Acceptor Predicted Sites: {total_stats['total_acceptor_pred']}\")\n",
    "#     print(f\"Total Acceptor Matches: {total_stats['total_acceptor_matches']}\")\n",
    "    \n",
    "#     print(f\"\\nTotal Donor Ground Truth Sites: {total_stats['total_donor_gt']}\")\n",
    "#     print(f\"Total Donor Predicted Sites: {total_stats['total_donor_pred']}\")\n",
    "#     print(f\"Total Donor Matches: {total_stats['total_donor_matches']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694e677-fcab-4bd2-9103-a4def017cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnose_splice_site_alignment(\n",
    "#     acceptor_ground_truth, \n",
    "#     donor_ground_truth, \n",
    "#     acceptor_predictions, \n",
    "#     donor_predictions\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e87de3-25d1-45a5-9a33-eeabe708b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "with open('acceptor_predictions.pkl', 'rb') as f:\n",
    "    donor_pred = pickle.load(f)\n",
    "\n",
    "# Create new dictionary for corrected predictions\n",
    "corrected = {}\n",
    "\n",
    "# Shift each chromosome's predictions\n",
    "for chrom in donor_pred:\n",
    "    original = donor_pred[chrom]  # Get array for chromosome\n",
    "    shifted = np.zeros_like(original)  # Create zero array same size\n",
    "    shifted[1:] = original[:-1]  # Shift values right by 1\n",
    "    corrected[chrom] = shifted\n",
    "\n",
    "# Save corrected predictions\n",
    "with open('donor_predictions_corrected.pkl', 'wb') as f:\n",
    "    pickle.dump(corrected, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
